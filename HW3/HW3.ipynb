{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li0bVCTuxc6n"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "#### Lab 3\n",
        "\n",
        "# National Tsing Hua University\n",
        "\n",
        "#### Spring 2025\n",
        "\n",
        "#### 11320IEEM 513600\n",
        "\n",
        "#### Deep Learning and Industrial Applications\n",
        "    \n",
        "## Lab 3: Anomaly Detection in Industrial Applications\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlvflhYwCu8Q"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "In today's industrial landscape, the ability to detect anomalies in manufacturing processes and products is critical for maintaining quality, efficiency, and safety. This lab focuses on leveraging deep learning techniques for anomaly detection in various industrial applications, using the MVTEC Anomaly Detection Dataset. By employing ImageNet-pretrained models available in torchvision, students will gain hands-on experience in classfying defects and irregularities across different types of industrial products.\n",
        "\n",
        "Throughout this lab, you'll be involved in the following key activities:\n",
        "- Explore and process the MVTec Anomaly Detection Dataset.\n",
        "- Apply ImageNet-pretrained models from [Torchvision](https://pytorch.org/vision/stable/models.html) to detect anomalies in industrial products.\n",
        "- Evaluate the performance of the models to understand their effectiveness in real-world industrial applications.\n",
        "\n",
        "### Objectives\n",
        "\n",
        "- Understand the principles of anomaly detection in the context of industrial applications.\n",
        "- Learn how to implement and utilize ImageNet-pretrained models for detecting anomalies.\n",
        "- Analyze and interpret the results of the anomaly detection models to assess their practicality in industrial settings.\n",
        "\n",
        "### Dataset\n",
        "\n",
        "The MVTec AD Dataset is a comprehensive collection of high-resolution images across different categories of industrial products, such as bottles, cables, and metal nuts, each with various types of defects. This dataset is pivotal for developing and benchmarking anomaly detection algorithms. You can download our lab's dataset [here](https://drive.google.com/file/d/19600hUOpx0hl78TdpdH0oyy-gGTk_F_o/view?usp=share_link). You can drop downloaded data and drop to colab, or you can put into yor google drive.\n",
        "\n",
        "### References\n",
        "- [MVTec AD Dataset](https://www.kaggle.com/datasets/ipythonx/mvtec-ad/data) for the dataset used in this lab.\n",
        "- [Torchvision Models](https://pytorch.org/vision/stable/models.html) for accessing ImageNet-pretrained models to be used in anomaly detection tasks.\n",
        "- [State-of-the-Art Anomaly Detection on MVTec AD](https://paperswithcode.com/sota/anomaly-detection-on-mvtec-ad) for insights into the latest benchmarks and methodologies in anomaly detection applied to the MVTec AD dataset.\n",
        "- [CVPR 2019: MVTec AD — A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection] for the original paper of MVTec AD dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuiEw1L0Cu8Q"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXfjTWKUCu8R"
      },
      "outputs": [],
      "source": [
        "file_paths = glob.glob('bottle/train/good/*.png')\n",
        "file_paths = sorted([\n",
        "    path for path in file_paths \n",
        "    if os.path.basename(path) in [f'{i:03}.png' for i in range(10)]\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3GiOZBRJCu8S"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 79.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10, 900, 900, 3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "all_data = []\n",
        "\n",
        "for img in tqdm(file_paths):\n",
        "    img = cv2.imread(img)\n",
        "    img = img[..., ::-1]\n",
        "    all_data.append(img)\n",
        "\n",
        "all_data = np.stack(all_data)\n",
        "print(all_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train folder stats: {'good': 209}\n",
            "Test folder stats: {'broken_large': 20, 'broken_small': 22, 'contamination': 21, 'good': 20}\n"
          ]
        }
      ],
      "source": [
        "root_dir = \"bottle\"\n",
        "train_dir = os.path.join(root_dir, \"train\")\n",
        "test_dir  = os.path.join(root_dir, \"test\")\n",
        "\n",
        "def count_images_in_subfolders(folder):\n",
        "    # 回傳一個 dict，key 是子資料夾名稱，value 是該子資料夾中的影像數量\n",
        "    result = {}\n",
        "    # 列出 folder 下所有子資料夾 (例如 good, broken_large 等)\n",
        "    subfolders = [d for d in os.listdir(folder) if os.path.isdir(os.path.join(folder, d))]\n",
        "    for subf in subfolders:\n",
        "        subf_path = os.path.join(folder, subf)\n",
        "        # 找該子資料夾底下的所有 png (或你可改成 *.jpg, *.bmp 等)\n",
        "        images = glob.glob(os.path.join(subf_path, \"*.png\"))\n",
        "        result[subf] = len(images)\n",
        "    return result\n",
        "\n",
        "# 統計 train 資料夾\n",
        "train_stats = count_images_in_subfolders(train_dir)\n",
        "print(\"Train folder stats:\", train_stats)\n",
        "\n",
        "# 統計 test 資料夾\n",
        "test_stats = count_images_in_subfolders(test_dir)\n",
        "print(\"Test folder stats:\", test_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-1PsC--M7pT"
      },
      "source": [
        "## Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "\n",
        "class MVTecDataset(Dataset):\n",
        "    \"\"\"\n",
        "    自訂 Dataset 以處理 MVTec AD 的 bottle 資料集。\n",
        "    訓練階段只載入正常(good)影像；測試階段則載入所有影像，\n",
        "    並將 good 標記為 0，缺陷影像標記為 1。\n",
        "    \"\"\"\n",
        "    def __init__(self, root_dir, phase='train', transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (str): 資料集根目錄，例如 'bottle'\n",
        "            phase (str): 'train' 或 'test'\n",
        "            transform: 影像預處理（torchvision transforms）\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.phase = phase\n",
        "        self.transform = transform\n",
        "        \n",
        "        self.image_paths = []\n",
        "        self.labels = []  # 正常為 0，異常(任何 defect)為 1\n",
        "        \n",
        "        if phase == 'train':\n",
        "            # 只讀取 train/good 資料夾內的影像\n",
        "            good_dir = os.path.join(root_dir, 'train', 'good')\n",
        "            self.image_paths = glob.glob(os.path.join(good_dir, '*.png'))\n",
        "            self.labels = [0] * len(self.image_paths)\n",
        "        elif phase == 'test':\n",
        "            # 測試階段，讀取 test 資料夾下所有子資料夾的影像\n",
        "            test_dir = os.path.join(root_dir, 'test')\n",
        "            # 列出所有子資料夾，例如 'good', 'bad_marking', 'broken_large', 等\n",
        "            subfolders = [d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))]\n",
        "            for folder in subfolders:\n",
        "                folder_path = os.path.join(test_dir, folder)\n",
        "                # 使用 glob 取得該資料夾下所有 png 檔\n",
        "                images = glob.glob(os.path.join(folder_path, '*.png'))\n",
        "                self.image_paths.extend(images)\n",
        "                # 若資料夾為 'good' 則標記為 0，其它標記為 1 (異常)\n",
        "                if folder == 'good':\n",
        "                    self.labels.extend([0] * len(images))\n",
        "                else:\n",
        "                    self.labels.extend([1] * len(images))\n",
        "        else:\n",
        "            raise ValueError(\"phase 必須是 'train' 或 'test'\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # 讀取影像 (OpenCV 預設 BGR)\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise RuntimeError(f\"無法讀取影像: {image_path}\")\n",
        "        # 轉換成 RGB\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # 若有 transform，使用 transform 處理\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        else:\n",
        "            # 否則轉換為 tensor 並正規化到 [0,1]\n",
        "            image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Attempt 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定義帶有 data augmentation 的影像預處理\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)), \n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = MVTecDataset(root_dir, phase='train', transform=train_transform)\n",
        "test_dataset  = MVTecDataset(root_dir, phase='test', transform=test_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Tiffany\\.conda\\envs\\pyt\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tiffany\\.conda\\envs\\pyt\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "設定異常判斷閾值: 4.221568\n"
          ]
        }
      ],
      "source": [
        "# 載入預訓練的 ResNet18 並移除最後一層（fc）\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "resnet = models.resnet18(pretrained=True)\n",
        "resnet.fc = nn.Identity()  # 將 fc 層設為 identity，使輸出為特徵向量\n",
        "resnet = resnet.to(device)\n",
        "resnet.eval()\n",
        "\n",
        "# 以訓練集 good 影像萃取特徵\n",
        "train_features = []\n",
        "with torch.no_grad():\n",
        "    for images, _ in train_loader:\n",
        "        images = images.to(device)\n",
        "        feats = resnet(images)  # 輸出 shape: (batch, feature_dim)\n",
        "        train_features.append(feats.cpu())\n",
        "train_features = torch.cat(train_features, dim=0)  # shape: (N, feature_dim)\n",
        "\n",
        "# 計算訓練集特徵平均向量，並以歐氏距離作為 anomaly score\n",
        "mean_feat = train_features.mean(dim=0)\n",
        "train_dists = torch.norm(train_features - mean_feat, dim=1)\n",
        "# 設定閾值為訓練特徵距離的平均值 + 3 倍標準差\n",
        "threshold = train_dists.mean().item() + 3 * train_dists.std().item()\n",
        "print(f\"設定異常判斷閾值: {threshold:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9157\n"
          ]
        }
      ],
      "source": [
        "# 測試階段：根據特徵距離進行 anomaly 判斷\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        feats = resnet(images)\n",
        "        dists = torch.norm(feats.cpu() - mean_feat, dim=1)\n",
        "        preds = (dists > threshold).int()  # 若距離超過閾值，則標記 anomaly (1)\n",
        "        all_preds.extend(preds.numpy())\n",
        "        all_labels.extend(labels)\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "accuracy = (all_preds == all_labels).mean()\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Attempt 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定義帶有 data augmentation 的影像預處理\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = MVTecDataset(root_dir, phase='train', transform=train_transform)\n",
        "test_dataset  = MVTecDataset(root_dir, phase='test', transform=test_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "初始中心向量計算完成.\n",
            "Epoch 1/10, Loss: 482.657778\n",
            "Epoch 2/10, Loss: 395.066864\n",
            "Epoch 3/10, Loss: 349.092155\n",
            "Epoch 4/10, Loss: 318.232231\n",
            "Epoch 5/10, Loss: 295.867916\n",
            "Epoch 6/10, Loss: 279.359445\n",
            "Epoch 7/10, Loss: 266.921362\n",
            "Epoch 8/10, Loss: 257.392767\n",
            "Epoch 9/10, Loss: 249.888794\n",
            "Epoch 10/10, Loss: 243.871802\n",
            "設定異常判斷閾值: 15.765369\n"
          ]
        }
      ],
      "source": [
        "# 載入預訓練的 ResNet18 並移除最後一層\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Identity()  # 使輸出為特徵向量\n",
        "model = model.to(device)\n",
        "\n",
        "# 計算初始中心向量 c (以所有訓練集 good 影像的特徵平均)\n",
        "model.eval()\n",
        "train_features = []\n",
        "with torch.no_grad():\n",
        "    for images, _ in train_loader:\n",
        "        images = images.to(device)\n",
        "        feats = model(images)  # shape: (batch, feature_dim)\n",
        "        train_features.append(feats.cpu())\n",
        "train_features = torch.cat(train_features, dim=0)\n",
        "center = train_features.mean(dim=0).to(device)\n",
        "print(\"初始中心向量計算完成.\")\n",
        "\n",
        "# 進行 fine tune (Deep SVDD 目標: 最小化每張影像特徵與 center 的平方距離)\n",
        "model.train()\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, _ in train_loader:\n",
        "        images = images.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        feats = model(images)\n",
        "        # Deep SVDD loss: 平均每個樣本的 squared distance to center\n",
        "        loss = ((feats - center) ** 2).sum(dim=1).mean()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.6f}\")\n",
        "\n",
        "# 使用 fine tune 後的模型計算訓練集特徵距離，並設定 anomaly 判斷閾值\n",
        "model.eval()\n",
        "finetune_train_features = []\n",
        "with torch.no_grad():\n",
        "    for images, _ in train_loader:\n",
        "        images = images.to(device)\n",
        "        feats = model(images)\n",
        "        finetune_train_features.append(feats.cpu())\n",
        "finetune_train_features = torch.cat(finetune_train_features, dim=0)\n",
        "train_dists = torch.norm(finetune_train_features - center.cpu(), dim=1)\n",
        "threshold = train_dists.mean().item() + 3 * train_dists.std().item()\n",
        "print(f\"設定異常判斷閾值: {threshold:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9759\n"
          ]
        }
      ],
      "source": [
        "# 測試階段：根據 fine tune 後的特徵距離進行 anomaly 判斷\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        feats = model(images)\n",
        "        dists = torch.norm(feats.cpu() - center.cpu(), dim=1)\n",
        "        preds = (dists > threshold).int()  # 超過閾值則視為 anomaly (1)\n",
        "        all_preds.extend(preds.numpy())\n",
        "        all_labels.extend(labels.numpy())\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "accuracy = (all_preds == all_labels).mean()\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Attempt 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定義帶有 data augmentation 的影像預處理\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),   \n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = MVTecDataset(root_dir, phase='train', transform=train_transform)\n",
        "test_dataset  = MVTecDataset(root_dir, phase='test', transform=test_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Tiffany\\.conda\\envs\\pyt\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tiffany\\.conda\\envs\\pyt\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\Tiffany/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [07:04<00:00, 1.30MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "設定異常判斷閾值: 57.693165\n"
          ]
        }
      ],
      "source": [
        "# 載入預訓練的 VGG16 並移除 classifier 部分，使輸出為特徵向量\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "vgg16.classifier = nn.Identity()  # 使模型直接輸出展平後的特徵 (形狀通常為 [N, 25088])\n",
        "vgg16 = vgg16.to(device)\n",
        "vgg16.eval()\n",
        "\n",
        "# 以訓練集 good 影像萃取特徵\n",
        "train_features = []\n",
        "with torch.no_grad():\n",
        "    for images, _ in train_loader:\n",
        "        images = images.to(device)\n",
        "        feats = vgg16(images)  # 輸出 shape: (batch, feature_dim)\n",
        "        train_features.append(feats.cpu())\n",
        "train_features = torch.cat(train_features, dim=0)  # shape: (N, feature_dim)\n",
        "\n",
        "# 計算訓練集特徵平均向量，並以歐氏距離作為 anomaly score\n",
        "mean_feat = train_features.mean(dim=0)\n",
        "train_dists = torch.norm(train_features - mean_feat, dim=1)\n",
        "# 設定閾值為訓練特徵距離的平均值 + 3 倍標準差\n",
        "threshold = train_dists.mean().item() + 3 * train_dists.std().item()\n",
        "print(f\"設定異常判斷閾值: {threshold:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9277\n"
          ]
        }
      ],
      "source": [
        "# 測試階段：根據特徵距離進行 anomaly 判斷\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        feats = vgg16(images)\n",
        "        dists = torch.norm(feats.cpu() - mean_feat, dim=1)\n",
        "        preds = (dists > threshold).int()  # 超過閾值則視為 anomaly (1)\n",
        "        all_preds.extend(preds.numpy())\n",
        "        all_labels.extend(labels.numpy())\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "accuracy = (all_preds == all_labels).mean()\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Attempt 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定義帶有 data augmentation 的影像預處理\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),  \n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = MVTecDataset(root_dir, phase='train', transform=train_transform)\n",
        "test_dataset  = MVTecDataset(root_dir, phase='test', transform=test_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Tiffany\\.conda\\envs\\pyt\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "初始中心向量計算完成.\n",
            "Epoch 1/10, Loss: 440.068024\n",
            "Epoch 2/10, Loss: 358.512120\n",
            "Epoch 3/10, Loss: 305.928372\n",
            "Epoch 4/10, Loss: 267.261707\n",
            "Epoch 5/10, Loss: 237.807198\n",
            "Epoch 6/10, Loss: 214.617036\n",
            "Epoch 7/10, Loss: 195.469256\n",
            "Epoch 8/10, Loss: 179.644788\n",
            "Epoch 9/10, Loss: 166.266373\n",
            "Epoch 10/10, Loss: 154.868164\n",
            "設定異常判斷閾值: 16.041825\n"
          ]
        }
      ],
      "source": [
        "# 載入預訓練的 VGG16 並移除 classifier 部分，使模型輸出展平後的特徵向量\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "vgg16.classifier = nn.Identity()  # 輸出特徵向量 (形狀通常為 [N, 25088])\n",
        "\n",
        "for param in vgg16.features[:15].parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "vgg16 = vgg16.to(device)\n",
        "\n",
        "# 計算初始中心向量 c (利用所有訓練集 good 影像)\n",
        "vgg16.eval()\n",
        "train_features = []\n",
        "with torch.no_grad():\n",
        "    for images, _ in train_loader:\n",
        "        images = images.to(device)\n",
        "        feats = vgg16(images)\n",
        "        train_features.append(feats.cpu())\n",
        "train_features = torch.cat(train_features, dim=0)\n",
        "center = train_features.mean(dim=0).to(device)\n",
        "print(\"初始中心向量計算完成.\")\n",
        "\n",
        "# Fine tune 階段：使用 Deep SVDD Loss (最小化每張影像特徵與 center 的平方距離)\n",
        "vgg16.train()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, vgg16.parameters()), lr=1e-5)\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, _ in train_loader:\n",
        "        images = images.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        feats = vgg16(images)\n",
        "        loss = ((feats - center) ** 2).sum(dim=1).mean()  # squared Euclidean distance\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.6f}\")\n",
        "\n",
        "# 計算 fine tune 後的訓練集特徵距離，並設定 anomaly 判斷閾值\n",
        "vgg16.eval()\n",
        "finetune_train_features = []\n",
        "with torch.no_grad():\n",
        "    for images, _ in train_loader:\n",
        "        images = images.to(device)\n",
        "        feats = vgg16(images)\n",
        "        finetune_train_features.append(feats.cpu())\n",
        "finetune_train_features = torch.cat(finetune_train_features, dim=0)\n",
        "train_dists = torch.norm(finetune_train_features - center.cpu(), dim=1)\n",
        "threshold = train_dists.mean().item() + 3 * train_dists.std().item()\n",
        "print(f\"設定異常判斷閾值: {threshold:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9639\n"
          ]
        }
      ],
      "source": [
        "# 測試階段：根據 fine tune 後的特徵距離進行 anomaly 判斷\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        feats = vgg16(images)\n",
        "        dists = torch.norm(feats.cpu() - center.cpu(), dim=1)\n",
        "        preds = (dists > threshold).int()  # 距離超過閾值則判定 anomaly (1)\n",
        "        all_preds.extend(preds.numpy())\n",
        "        all_labels.extend(labels.numpy())\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "accuracy = (all_preds == all_labels).mean()\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
